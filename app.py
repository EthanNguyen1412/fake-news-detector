import streamlit as st
import pickle
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from lime.lime_text import LimeTextExplainer
import numpy as np

# --- T·∫¢I MODEL V√Ä VECTORIZER ƒê√É L∆ØU ---
try:
    with open('saved_model/model.pkl', 'rb') as f:
        model = pickle.load(f)
    with open('saved_model/vectorizer.pkl', 'rb') as f:
        vectorizer = pickle.load(f)
except FileNotFoundError:
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y t·ªáp model.pkl ho·∫∑c vectorizer.pkl. Vui l√≤ng ch·∫°y notebook Model_Training.ipynb tr∆∞·ªõc.")
    st.stop()


# --- H√ÄM TI·ªÄN X·ª¨ L√ù (gi·ªëng l√∫c hu·∫•n luy·ªán) ---
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'<.*?>+', '', text)
    text = re.sub(r'\w*\d\w*', '', text)
    return text

# --- H√ÄM T·∫†O GI·∫¢I TH√çCH V·ªöI LIME ---
# LIME c·∫ßn m·ªôt h√†m d·ª± ƒëo√°n tr·∫£ v·ªÅ x√°c su·∫•t cho c·∫£ 2 l·ªõp
def predictor(texts):
    processed_texts = [preprocess_text(text) for text in texts]
    feature_vectors = vectorizer.transform(processed_texts)
    # model.decision_function tr·∫£ v·ªÅ ƒëi·ªÉm s·ªë, ta c·∫ßn chuy·ªÉn sang x√°c su·∫•t
    # ·ªû ƒë√¢y d√πng m·ªôt x·∫•p x·ªâ ƒë∆°n gi·∫£n, th·ª±c t·∫ø c√≥ th·ªÉ d√πng CalibratedClassifierCV
    # Nh∆∞ng v·ªõi PAC v√† LIME, decision_function th∆∞·ªùng ƒë·ªß t·ªët
    scores = model.decision_function(feature_vectors)
    # Chuy·ªÉn ƒëi·ªÉm s·ªë th√†nh "x√°c su·∫•t" gi·∫£ ƒë·ªãnh cho 2 l·ªõp [P(Fake), P(True)]
    probs = np.array([[1 - 1 / (1 + np.exp(-s)), 1 / (1 + np.exp(-s))] for s in scores])
    return probs

# Kh·ªüi t·∫°o LIME explainer
explainer = LimeTextExplainer(class_names=['Tin gi·∫£', 'Tin th·∫≠t'])


# --- GIAO DI·ªÜN STREAMLIT ---
st.set_page_config(page_title="Tr√¨nh ph√°t hi·ªán Tin gi·∫£", layout="wide")
st.title("üîé AI Ph√°t Hi·ªán Tin T·ª©c Gi·∫£")
st.markdown("Nh·∫≠p m·ªôt ƒëo·∫°n vƒÉn b·∫£n tin t·ª©c (ti·∫øng Anh) v√†o √¥ d∆∞·ªõi ƒë√¢y ƒë·ªÉ AI d·ª± ƒëo√°n ƒë·ªô tin c·∫≠y.")

# √î nh·∫≠p li·ªáu
input_text = st.text_area("Nh·∫≠p n·ªôi dung tin t·ª©c t·∫°i ƒë√¢y:", height=250)

if st.button("Ki·ªÉm tra"):
    if input_text.strip() == "":
        st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung tin t·ª©c.")
    else:
        # 1. D·ª± ƒëo√°n
        prediction = model.predict(vectorizer.transform([preprocess_text(input_text)]))
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        st.subheader("K·∫øt qu·∫£ D·ª± ƒëo√°n")
        if prediction[0] == 1:
            st.success("‚úÖ Tin n√†y c√≥ v·∫ª l√† **TIN TH·∫¨T**.")
        else:
            st.error("‚ùå Tin n√†y c√≥ v·∫ª l√† **TIN GI·∫¢**.")
            
        # 2. Gi·∫£i th√≠ch l√Ω do v·ªõi LIME
        st.subheader("Gi·∫£i th√≠ch c·ªßa AI")
        with st.spinner("ƒêang ph√¢n t√≠ch l√Ω do..."):
            explanation = explainer.explain_instance(
                preprocess_text(input_text),
                predictor,
                num_features=10, # S·ªë l∆∞·ª£ng t·ª´ kh√≥a mu·ªën gi·∫£i th√≠ch
                labels=(1,) # Ch·ªâ gi·∫£i th√≠ch cho l·ªõp "Tin th·∫≠t"
            )
            
            # Hi·ªÉn th·ªã gi·∫£i th√≠ch d∆∞·ªõi d·∫°ng HTML
            st.components.v1.html(explanation.as_html(), height=800, scrolling=True)